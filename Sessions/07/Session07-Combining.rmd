---
title: "SCRGOT 2023 Coder Upgrade Session 07 - Combining single cell datasets"
author: "Ryan Roberts"
date: "4/16/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(rrrSingleCellUtils)
library(Seurat)
library(parallel)

theme_set(theme_classic())
```

## Introduction to the datasets

Within the accompanying "Datasets" folder, you will find two RData files, each containing a collection of single cell datasets. I have taken care of a lot of pre-processing for you, so that you can focus during this workshop on integrating the datasets. 

The "patient_tumors.RData" file contains two data objects, each of these in turn containing a list of Seurat objects. These data originated from scRNA-seq performed directly on primary bone tumors resected from patients, then processed to produce single cell libraries and sequenced (10X 3' workflow). These data were downloaded from the GEO database (GSE162454). Each element of each list contains cells from the same tumor. The list named "pt_tumor" contains subsets of the tumor cells from each sample and the "pt_stroma" list contains subsets of the stromal cells identified in same samples (I already took care of all that for you). The names of each element in the list (OS_1, OS_2, etc) are the patient IDs reported in the publication. Note that each of these samples was collected from a different patient on a different day, sometimes in a different lab, and processed separately from all of the others. All of the cells in both data objects are human.

The "xeno_tumors.RData" file contains two similarly-structured lists of Seurat objects from a mouse xenograft experiment, where immunodeficient mice were injected by tail vein with human bone tumor cells to produce metastatic lung tumors. Lungs were then harvested at several timepoints and processed on the day of harvest to produce single cell libraries that were sequenced. These samples each contain the same tumor cells, harvested at different stages along the path toward metastatic colonization, but also contain the surrounding lung cells (isolated using a niche labeling technique). Importantly, the "xeno_tumors" object is a list containing human tumor cells, while the "xeno_stroma" object contains murine stromal cells--the sequenced libraries were aligned to a mixed human/mouse genome.

Start by practicing your skills learned yesterday in the Intro session to take one Seurat object within the "pt_tumor" list to a UMAP plot. HINT: Read10x,  CreateSeuratObject, PercentageFeatureSet, VlnPlot, subset are all done. You'll need to run NormalizeData, FindVariableFeatures, ScaleData, RunPCA, FindNeighbors, FindClusters, RunUMAP, DimPlot.

```{r}
load("Datasets/patient_tumors.RData")

t1 <- pt_tumor[[5]] %>%
    NormalizeData() %>%
    FindVariableFeatures() %>%
    ScaleData() %>%
    RunPCA() %>%
    FindNeighbors() %>%
    FindClusters() %>%
    RunUMAP(dims = 1:30)

DimPlot(t1, pt.size = 1, label = TRUE) +
    ggtitle("Sample OS_5 - initial clustering") +
    coord_fixed()
```

# Merging datasets

The first step toward combining multiple datasets is to move all of the normalized data (from all of the objects that you want to combine) into a single Seurat object. This is best accomplished by creating a list of individual Seurat objects (which I've already done for you), then using the merge command to combine them into one. 

You need to have a little forethought in the way that you do this. If you don't create metadata variables that will track the origins of each cell, when the cells are all combined together, you won't be able to tell which cells came from which samples.

Step-by-step instructions:
1. (I already did this for you) Create a list containing individual Seurat objects representing each of the datasets in the "PatientTumors" folder. You have three options for how you might approach this:
    - Acceptable: create each of the Seurat objects separately, then combine them into a list using the list() command.
    - Better: create a for() loop that loops through code to create the Seurat objects, adding them to the list object without an intermediate (the individual Seurat object).
    - Best: create a dataframe, tibble, or list of vectors containing all of the variables that you will need to create the list of Seurat objects and a function to create a normalized Seurat object and add metadata, then use lapply to map the dataframe to the function, building the list of Seurat objects in a single step. (This is the most computationally efficient and flexible way to do it, and you can reuse the function you build over and over).
2. (Start here with the "pt_tumor" data set) Merge these into a single Seurat object using the merge() command. Candidly, this is a super awkward function, so I'll lay out for you the way it should look:
    
    combined_object <- merge(seurat_list[[1]], seurat_list[2:length(seurat_list)], add.cell.ids = sample_list)

The first element of the merge() is the first object that you want to combine, The second is "the rest" of the elements that you want to combine, and the add.cell.ids is a prefix added to the cell barcodes, in case some of them are the same from one sample to another (they won't get mistakenly put together or crash the operation because they're not unique if you use this option).
3. Perform all the usual operations to process your dataset, just like you did for the individual Seurat objects--FindVariableFeatures, ScaleData, yada yada yada through RunUMAP.
4. Now plot the data to see what you have. This is an important decision point. Based on the nature of the samples/dataset, the details surrounding how they were created, and the scientific question you intend to ask, you need to decide whether or not this will work without alignment, or whether it needs to be aligned (and what you'll use to attempt alignment/batch correction, if you do choose to use it). To check out how well aligned (or not) your data is, use the group.by and split.by options of DimPlot to use that metadata element you added earlier to either color by source or panel by source, respectively.
5. Are your samples clustering by sample or by cell type or a little of both?
6. In this example, we have tumor cells that seem very different one from the next, but stromal cells that might be similar. Repeat this process with the "pt_stroma" Seurat objects and compare results.

```{r}
# Build a list of samples to import
sample_list <- c("0Weeks", "2Weeks", "3Weeks", "5Weeks")

# Write a function to import a sample (be sure to label where it came from)
create_seurat <- function(x) {
    message(paste("Loading", x, "..."))
    s <- tenx_load_qc(paste0("Datasets/XenoTumors/", x), species_pattern = "^mm10-") 
    s$src <- x
    message(paste("Sample", x, "is loaded."))
    return(s)
}

# Map the sample_list to the create_seurat function with lapply to generate
# a list of Seurat objects
stroma <- mclapply(sample_list, create_seurat, mc.cores = 4L)
names(stroma) <- sample_list

violins <- list()
for(t in names(stroma)) {
    violins[[t]] <- VlnPlot(stroma[[t]],
        features = c("nFeature_RNA", "nCount_RNA", "percent.mt")) +
        plot_annotation(title = t,
            theme = theme(plot.title = element_text(size = 16)))
}

wrap_plots(violins, ncol = 2)

qc <- data.frame(
    sample = sample_list,
    ncount = c(20000, 6500, 25000, 25000),
    mtpercent = c(13, 13, 13, 13)
)

patient_tumor <- mclapply(seq_along(stroma), function(i) {
    x <- stroma[[i]] %>%
        subset(subset = nCount_RNA < qc$ncount[i] &
            percent.mt < qc$mtpercent[i]) %>%
        NormalizeData() %>%
        FindVariableFeatures() %>%
        ScaleData() %>%
        RunPCA() %>%
        FindNeighbors() %>%
        FindClusters() %>%
        RunUMAP(dims = 1:30)
    return(x)
})
names(patient_tumor) <- names(stroma)

dsample <- 500
stroma <- lapply(patient_tumor, function(x) {
    s <- x
    cell_list <- colnames(s)
    samp_number <- min(dsample, length(cell_list))
    cell_list <- sample(cell_list, samp_number)
    s <- subset(s, cells = cell_list)
    return(s)
})





```

#########################################################################
## Section 2: Comparing two integration methods: Harmony and CCA.     
#########################################################################

# Introduction to compare current integration methods (10-15 min)

    -- Different integration method overview
    -- Factors to consider when chooseing an integration methods: project biological variations, batch effect.
    -- Visualization and intepretion of integrated data
    -- Assessment of integration quality
    -- Challenges and limitations


# Training session: this section will compare two widely used methods -- harmony and CCA. (20-30 min)

Method Description:
    -- Merge objects
    -- Run with harmony
    -- Run with CCA
    -- Visualie results from haramony and CCA

Dataset Description: this tutorial will have four samples, 
    -- two replicates from human normal kidney (GSM5627690, GSM5627691), 
    -- two replicates from  autosomal dominant polycystic kidney disease (GSM5627695 and GSM5627696).
    
Note: The dataset can be downloaded from GEO:GSE185948 : https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE185948 
Dataset reference: Muto Y, Dixon EE, Yoshimura Y, Wu H et al. Defining cellular complexity in human autosomal dominant polycystic kidney disease by multimodal single cell analysis. Nat Commun 2022 Oct 30;13(1):6497. PMID: 36310237
To reduce the time, We randomly select 1000 of cells in each sample. Please download the datasets from OneDrive.
https://nationwidechildrens-my.sharepoint.com/:u:/r/personal/katherine_miller_nationwidechildrens_org/Documents/SCRGOT/2023%20Coder%20Upgrade/Sessions/07-Integration/KidneyDatasets.zip?csf=1&web=1&e=cSDEwB


# Step 2.1: Load the packages and setting the working environment.

```{r setup, include=FALSE}
# Load the packages. 
# If you cannot load the packages, please download and install them: install.packages("harmony"); install.packages("gridExtra")
library(harmony)
library(Seurat)
library(gridExtra)
library(ggplot2)
library(tidyverse)

# Please remember to set up your work directory. 
# We set up the directory into folder where we downloaded the datasets
getwd() # if you want to get the current directory.
setwd("/Users/XXW004/Documents/Projects/LectureForSingleCellGroup/IntegrationSection/TestDatasets/") # If you want to set up the work diretory

# Check the files in the current directory. 
Datafiles<-list.files(path = "./", recursive = F, full.names = F)
Datafiles

```

# Step 2.2: Read the objects.

```{r}
# We used for loop to read the objects, add group column for each meta object, and save the object into a list accordingly to their names.

# Create an empty list to store the objects
myobjectlist<- list()

# Read the objects, assigan the name to the object, create a group to show the name of sample, and store these objects into a list

for (x in Datafiles){

  ## find the file with the substring of ".small.rds", then replace with empty string
  name <- gsub (".small.rds","", x)
  
  ## loading the RDS file
  rds<- readRDS(file = x)
  
  ## check the size of each objects
  dim(rds)
 
  ## using the assign the name to the objects
  assign (name, rds)
  
  ## create a group that show the name of samples
  rds$group <- rep(name, length(rds$orig.ident))
  
  ## store these objects into list
  myobjectlist[[name]] <-rds
}

```

# Step 2.3: Briefly go through these objects to confirm the lists: size of the list, meta data

```{r}
# check the lists. In the list, we will have four objects with their corresponding names
myobjectlist

# Check how many objects in the list
length(myobjectlist)

# Check the first object meta data
myobjectlist[[1]]@meta.data

# Step 2.4: Merge the objects
## Merge multiple objects from the list, add cell id with different prefix, and create a project for the merged object.
scrna<-merge(x=myobjectlist[[1]], 
    y=c(myobjectlist[[2]], myobjectlist[[3]],myobjectlist[[4]]), 
    add.cell.ids = c("A","B","C","D"), 
    project="Integration")

# Check the structure of meta data
str(scrna@meta.data)

# View the meta data
View(scrna@meta.data)

```

# Step 2.4: Quality control of merged objects

```{r}
## QC & filtering
## calculate mitochondrial percentatge
scrna$mitoPercent <-PercentageFeatureSet(scrna, pattern = '^MT-')

# let's check the quality of datasets by eveluating the mitochondrial percentage, number of Counts, number of features.
head(scrna@meta.data)
VlnPlot(scrna, features = c("mitoPercent", "nCount_RNA", "nFeature_RNA"))
VlnPlot(scrna, features = c("mitoPercent", "nCount_RNA", "nFeature_RNA") , split.by = 'group')

# filtering
scrna <- subset (scrna, subset =mitoPercent <10 & nFeature_RNA >500 & nCount_RNA >200 )

```

# Step 2.5: Standard normalization, variable feature finding, PCA and UMAP analyses, and Plot the merged objects

```{r}

# perform the standard workflow to figure out if there are any batch effects
scrna<- NormalizeData(object = scrna)
scrna<- FindVariableFeatures(object = scrna, nfeatures = 3000)
scrna<- ScaleData(object = scrna)
scrna<- RunPCA(object = scrna, npcs =15)
scrna<- RunUMAP(scrna, dims = 1:15)

# Visualize the dimplot by the merge function
BeforeHarmony<- DimPlot(scrna, reduction = "umap",split.by = 'group')
BeforeHarmony

```

# Step 2.6: Run with the harmony 

```{r}

# Before running Harmony, we need to confirm the metadata of our Seurat object contains one or several variables describing the factors we want to integrate on.
# We have defined the variable "group" to distinguish different samples.
# Double check:
levels(factor(scrna@meta.data$group))
scrna@meta.data

# note: we add a new reduction of 15 harmony 
seurat.harmony.integrated <- RunHarmony(scrna, group.by.vars = 'group', dims.use = 1:15, plot_convergence= FALSE, project.dim = F)

# Check the reduction after running harmony
seurat.harmony.integrated@reductions
seurat.harmony.integrated.embed <- Embeddings(seurat.harmony.integrated, "harmony")
seurat.harmony.integrated.embed[1:10,1:10]

# Check whether harmony integration is reflected in the visualization, we also generate UMAP using harmony reduction.
# Run Umap and clustering using Harmony reduction

seurat.harmony.integrated <- RunUMAP(seurat.harmony.integrated,reduction='harmony', dim=1:15)

# Run the cluster also need to set up the harmony reduction to find neighbor and clusters.
seurat.harmony.integrated<-FindNeighbors(seurat.harmony.integrated, reduction = 'harmony', dims = 1:15)
seurat.harmony.integrated<- FindClusters(seurat.harmony.integrated, resolution=1)


# Visualization of the dimplot using the harmony 
DimHarmony<-DimPlot(seurat.harmony.integrated, reduction = 'umap', split.by = 'group')
DimHarmony

```

# Step 2.7: Run with the canonical correlation analysis (CCA)

# Let's compare between CCA and Harmony.. 

```{r}
# Find integration anchor (CCA)
# for four split objects to perform the CCA method
# As we have already performed the QC, we used the objects listed above.

# Split the objects based on the group
SplitedObjects<- SplitObject(scrna, split.by = 'group')

# Check the split objects
SplitedObjects
length(SplitedObjects)

# Normalized dataset and Find variable features
for (i in 1: length(SplitedObjects)){
  SplitedObjects[[i]] <-NormalizeData(object = SplitedObjects[[i]])
  SplitedObjects[[i]] <- FindVariableFeatures(object = SplitedObjects[[i]],selection.method = "vst")
}

# Select integration features
features<- SelectIntegrationFeatures(object.list = SplitedObjects)
head(features)

# Find the integration anchor (CCA)
anchors<- FindIntegrationAnchors(object.list = SplitedObjects, anchor.features = features)

# Integrate data. This might take a longer time ...
seurat.integrated <- IntegrateData(anchorset = anchors)

# Scale data, run PCA and UMAP and visualize integrated data
seurat.integrated <- ScaleData(object = seurat.integrated)
seurat.integrated <- RunPCA(object = seurat.integrated)

# We can see from the PCA that a good overlay of several condtions by PCA
seurat.integrated<- FindNeighbors(seurat.integrated, dims = 1:15, reduction = "pca")
seurat.integrated <- FindClusters(seurat.integrated)
# Now, we can also visualize with UMAP.

seurat.integrated <- RunUMAP(object = seurat.integrated, dims = 1:15, reduction = "pca")

# Plot UMAP
DimPlot(seurat.integrated)

DimCCA <- DimPlot(seurat.integrated, reduction = 'umap', split.by  = 'group')
DimCCA

```

# Step 2.8: Compare two methods

```{r}

# Plot UMAPs from Harmony and CCA.
grid.arrange(DimHarmony, DimCCA,  ncol = 1, nrow=2)

# Potential way to evaluate the integration methods:
# Use the biomarkers from endothelium cells
FeaturePlot(seurat.harmony.integrated, features = c("PECAM1"), split.by = 'group', min.cutoff = 0.1)
FeaturePlot(seurat.integrated, features = c("PECAM1"), split.by = 'group', min.cutoff = 0.1)

```

## Break: 10 min

## Activity (20 min): Run the harmony with tumor datasets, and visualize the differences among harmony, merge and CCA.


## Discussion of single cell integration/batch correction methods

***
if you'd like to learn more:
 - https://doi.org/10.1371/journal.pcbi.1010492
 - https://doi.org/10.15252/msb.202110282
 - https://scvelo.readthedocs.io/en/stable/


## Session challenge

*** Winners will be selected based on the following principles:
 - how appropriate the analyses are for addressing the problem/question
 - how creative the approach is
 - how well the approach is documented
 - how beautifully/accessibly the results are presented

To submit your code for judging, just save a new file titled "Session7-Challenge-Ryan_Roberts.Rmd" (replacing my name with yours, obviously) in the "Challenges" folder on the SCRGOT Coder Upgrade OneDrive.

```{r}
***

```




